{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imblearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READING CSV FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./creditcard.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNDERSAMPLING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_frauds = len(df[df['Class'] == 1])\n",
    "non_fraud_indices = df[df.Class == 0].index\n",
    "non_fraud_indices = df[df.Class == 0].index\n",
    "random_indices = np.random.choice(non_fraud_indices, no_frauds, replace=False)\n",
    "fraud_indices = df[df.Class == 1].index\n",
    "under_sample_indices = np.concatenate([fraud_indices,random_indices])\n",
    "under_sample = df.loc[under_sample_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNDERSAMPLED DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>406.0</td>\n",
       "      <td>-2.312227</td>\n",
       "      <td>1.951992</td>\n",
       "      <td>-1.609851</td>\n",
       "      <td>3.997906</td>\n",
       "      <td>-0.522188</td>\n",
       "      <td>-1.426545</td>\n",
       "      <td>-2.537387</td>\n",
       "      <td>1.391657</td>\n",
       "      <td>-2.770089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517232</td>\n",
       "      <td>-0.035049</td>\n",
       "      <td>-0.465211</td>\n",
       "      <td>0.320198</td>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.177840</td>\n",
       "      <td>0.261145</td>\n",
       "      <td>-0.143276</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>472.0</td>\n",
       "      <td>-3.043541</td>\n",
       "      <td>-3.157307</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>2.288644</td>\n",
       "      <td>1.359805</td>\n",
       "      <td>-1.064823</td>\n",
       "      <td>0.325574</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>-0.270953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661696</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>-0.293803</td>\n",
       "      <td>0.279798</td>\n",
       "      <td>-0.145362</td>\n",
       "      <td>-0.252773</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>529.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>4462.0</td>\n",
       "      <td>-2.303350</td>\n",
       "      <td>1.759247</td>\n",
       "      <td>-0.359745</td>\n",
       "      <td>2.330243</td>\n",
       "      <td>-0.821628</td>\n",
       "      <td>-0.075788</td>\n",
       "      <td>0.562320</td>\n",
       "      <td>-0.399147</td>\n",
       "      <td>-0.238253</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294166</td>\n",
       "      <td>-0.932391</td>\n",
       "      <td>0.172726</td>\n",
       "      <td>-0.087330</td>\n",
       "      <td>-0.156114</td>\n",
       "      <td>-0.542628</td>\n",
       "      <td>0.039566</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>239.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6108</th>\n",
       "      <td>6986.0</td>\n",
       "      <td>-4.397974</td>\n",
       "      <td>1.358367</td>\n",
       "      <td>-2.592844</td>\n",
       "      <td>2.679787</td>\n",
       "      <td>-1.128131</td>\n",
       "      <td>-1.706536</td>\n",
       "      <td>-3.496197</td>\n",
       "      <td>-0.248778</td>\n",
       "      <td>-0.247768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573574</td>\n",
       "      <td>0.176968</td>\n",
       "      <td>-0.436207</td>\n",
       "      <td>-0.053502</td>\n",
       "      <td>0.252405</td>\n",
       "      <td>-0.657488</td>\n",
       "      <td>-0.827136</td>\n",
       "      <td>0.849573</td>\n",
       "      <td>59.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>7519.0</td>\n",
       "      <td>1.234235</td>\n",
       "      <td>3.019740</td>\n",
       "      <td>-4.304597</td>\n",
       "      <td>4.732795</td>\n",
       "      <td>3.624201</td>\n",
       "      <td>-1.357746</td>\n",
       "      <td>1.713445</td>\n",
       "      <td>-0.496358</td>\n",
       "      <td>-1.282858</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.379068</td>\n",
       "      <td>-0.704181</td>\n",
       "      <td>-0.656805</td>\n",
       "      <td>-1.632653</td>\n",
       "      <td>1.488901</td>\n",
       "      <td>0.566797</td>\n",
       "      <td>-0.010016</td>\n",
       "      <td>0.146793</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6331</th>\n",
       "      <td>7526.0</td>\n",
       "      <td>0.008430</td>\n",
       "      <td>4.137837</td>\n",
       "      <td>-6.240697</td>\n",
       "      <td>6.675732</td>\n",
       "      <td>0.768307</td>\n",
       "      <td>-3.353060</td>\n",
       "      <td>-1.631735</td>\n",
       "      <td>0.154612</td>\n",
       "      <td>-2.795892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.364514</td>\n",
       "      <td>-0.608057</td>\n",
       "      <td>-0.539528</td>\n",
       "      <td>0.128940</td>\n",
       "      <td>1.488481</td>\n",
       "      <td>0.507963</td>\n",
       "      <td>0.735822</td>\n",
       "      <td>0.513574</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6334</th>\n",
       "      <td>7535.0</td>\n",
       "      <td>0.026779</td>\n",
       "      <td>4.132464</td>\n",
       "      <td>-6.560600</td>\n",
       "      <td>6.348557</td>\n",
       "      <td>1.329666</td>\n",
       "      <td>-2.513479</td>\n",
       "      <td>-1.689102</td>\n",
       "      <td>0.303253</td>\n",
       "      <td>-3.139409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370509</td>\n",
       "      <td>-0.576752</td>\n",
       "      <td>-0.669605</td>\n",
       "      <td>-0.759908</td>\n",
       "      <td>1.605056</td>\n",
       "      <td>0.540675</td>\n",
       "      <td>0.737040</td>\n",
       "      <td>0.496699</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6336</th>\n",
       "      <td>7543.0</td>\n",
       "      <td>0.329594</td>\n",
       "      <td>3.712889</td>\n",
       "      <td>-5.775935</td>\n",
       "      <td>6.078266</td>\n",
       "      <td>1.667359</td>\n",
       "      <td>-2.420168</td>\n",
       "      <td>-0.812891</td>\n",
       "      <td>0.133080</td>\n",
       "      <td>-2.214311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156617</td>\n",
       "      <td>-0.652450</td>\n",
       "      <td>-0.551572</td>\n",
       "      <td>-0.716522</td>\n",
       "      <td>1.415717</td>\n",
       "      <td>0.555265</td>\n",
       "      <td>0.530507</td>\n",
       "      <td>0.404474</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6338</th>\n",
       "      <td>7551.0</td>\n",
       "      <td>0.316459</td>\n",
       "      <td>3.809076</td>\n",
       "      <td>-5.615159</td>\n",
       "      <td>6.047445</td>\n",
       "      <td>1.554026</td>\n",
       "      <td>-2.651353</td>\n",
       "      <td>-0.746579</td>\n",
       "      <td>0.055586</td>\n",
       "      <td>-2.678679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208828</td>\n",
       "      <td>-0.511747</td>\n",
       "      <td>-0.583813</td>\n",
       "      <td>-0.219845</td>\n",
       "      <td>1.474753</td>\n",
       "      <td>0.491192</td>\n",
       "      <td>0.518868</td>\n",
       "      <td>0.402528</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6427</th>\n",
       "      <td>7610.0</td>\n",
       "      <td>0.725646</td>\n",
       "      <td>2.300894</td>\n",
       "      <td>-5.329976</td>\n",
       "      <td>4.007683</td>\n",
       "      <td>-1.730411</td>\n",
       "      <td>-1.732193</td>\n",
       "      <td>-3.968593</td>\n",
       "      <td>1.063728</td>\n",
       "      <td>-0.486097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.589669</td>\n",
       "      <td>0.109541</td>\n",
       "      <td>0.601045</td>\n",
       "      <td>-0.364700</td>\n",
       "      <td>-1.843078</td>\n",
       "      <td>0.351909</td>\n",
       "      <td>0.594550</td>\n",
       "      <td>0.099372</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6446</th>\n",
       "      <td>7672.0</td>\n",
       "      <td>0.702710</td>\n",
       "      <td>2.426433</td>\n",
       "      <td>-5.234513</td>\n",
       "      <td>4.416661</td>\n",
       "      <td>-2.170806</td>\n",
       "      <td>-2.667554</td>\n",
       "      <td>-3.878088</td>\n",
       "      <td>0.911337</td>\n",
       "      <td>-0.166199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551180</td>\n",
       "      <td>-0.009802</td>\n",
       "      <td>0.721698</td>\n",
       "      <td>0.473246</td>\n",
       "      <td>-1.959304</td>\n",
       "      <td>0.319476</td>\n",
       "      <td>0.600485</td>\n",
       "      <td>0.129305</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6472</th>\n",
       "      <td>7740.0</td>\n",
       "      <td>1.023874</td>\n",
       "      <td>2.001485</td>\n",
       "      <td>-4.769752</td>\n",
       "      <td>3.819195</td>\n",
       "      <td>-1.271754</td>\n",
       "      <td>-1.734662</td>\n",
       "      <td>-3.059245</td>\n",
       "      <td>0.889805</td>\n",
       "      <td>0.415382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343283</td>\n",
       "      <td>-0.054196</td>\n",
       "      <td>0.709654</td>\n",
       "      <td>-0.372216</td>\n",
       "      <td>-2.032068</td>\n",
       "      <td>0.366778</td>\n",
       "      <td>0.395171</td>\n",
       "      <td>0.020206</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6529</th>\n",
       "      <td>7891.0</td>\n",
       "      <td>-1.585505</td>\n",
       "      <td>3.261585</td>\n",
       "      <td>-4.137422</td>\n",
       "      <td>2.357096</td>\n",
       "      <td>-1.405043</td>\n",
       "      <td>-1.879437</td>\n",
       "      <td>-3.513687</td>\n",
       "      <td>1.515607</td>\n",
       "      <td>-1.207166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.501543</td>\n",
       "      <td>-0.546869</td>\n",
       "      <td>-0.076584</td>\n",
       "      <td>-0.425550</td>\n",
       "      <td>0.123644</td>\n",
       "      <td>0.321985</td>\n",
       "      <td>0.264028</td>\n",
       "      <td>0.132817</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6609</th>\n",
       "      <td>8090.0</td>\n",
       "      <td>-1.783229</td>\n",
       "      <td>3.402794</td>\n",
       "      <td>-3.822742</td>\n",
       "      <td>2.625368</td>\n",
       "      <td>-1.976415</td>\n",
       "      <td>-2.731689</td>\n",
       "      <td>-3.430559</td>\n",
       "      <td>1.413204</td>\n",
       "      <td>-0.776941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454032</td>\n",
       "      <td>-0.577526</td>\n",
       "      <td>0.045967</td>\n",
       "      <td>0.461700</td>\n",
       "      <td>0.044146</td>\n",
       "      <td>0.305704</td>\n",
       "      <td>0.530981</td>\n",
       "      <td>0.243746</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6641</th>\n",
       "      <td>8169.0</td>\n",
       "      <td>0.857321</td>\n",
       "      <td>4.093912</td>\n",
       "      <td>-7.423894</td>\n",
       "      <td>7.380245</td>\n",
       "      <td>0.973366</td>\n",
       "      <td>-2.730762</td>\n",
       "      <td>-1.496497</td>\n",
       "      <td>0.543015</td>\n",
       "      <td>-2.351190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375026</td>\n",
       "      <td>0.145400</td>\n",
       "      <td>0.240603</td>\n",
       "      <td>-0.234649</td>\n",
       "      <td>-1.004881</td>\n",
       "      <td>0.435832</td>\n",
       "      <td>0.618324</td>\n",
       "      <td>0.148469</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6717</th>\n",
       "      <td>8408.0</td>\n",
       "      <td>-1.813280</td>\n",
       "      <td>4.917851</td>\n",
       "      <td>-5.926130</td>\n",
       "      <td>5.701500</td>\n",
       "      <td>1.204393</td>\n",
       "      <td>-3.035138</td>\n",
       "      <td>-1.713402</td>\n",
       "      <td>0.561257</td>\n",
       "      <td>-3.796354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.615642</td>\n",
       "      <td>-0.406427</td>\n",
       "      <td>-0.737018</td>\n",
       "      <td>-0.279642</td>\n",
       "      <td>1.106766</td>\n",
       "      <td>0.323885</td>\n",
       "      <td>0.894767</td>\n",
       "      <td>0.569519</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6719</th>\n",
       "      <td>8415.0</td>\n",
       "      <td>-0.251471</td>\n",
       "      <td>4.313523</td>\n",
       "      <td>-6.891438</td>\n",
       "      <td>6.796797</td>\n",
       "      <td>0.616297</td>\n",
       "      <td>-2.966327</td>\n",
       "      <td>-2.436653</td>\n",
       "      <td>0.489328</td>\n",
       "      <td>-3.371639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.536892</td>\n",
       "      <td>-0.546126</td>\n",
       "      <td>-0.605240</td>\n",
       "      <td>-0.263743</td>\n",
       "      <td>1.539916</td>\n",
       "      <td>0.523574</td>\n",
       "      <td>0.891025</td>\n",
       "      <td>0.572741</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6734</th>\n",
       "      <td>8451.0</td>\n",
       "      <td>0.314597</td>\n",
       "      <td>2.660670</td>\n",
       "      <td>-5.920037</td>\n",
       "      <td>4.522500</td>\n",
       "      <td>-2.315027</td>\n",
       "      <td>-2.278352</td>\n",
       "      <td>-4.684054</td>\n",
       "      <td>1.202270</td>\n",
       "      <td>-0.694696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743314</td>\n",
       "      <td>0.064038</td>\n",
       "      <td>0.677842</td>\n",
       "      <td>0.083008</td>\n",
       "      <td>-1.911034</td>\n",
       "      <td>0.322188</td>\n",
       "      <td>0.620867</td>\n",
       "      <td>0.185030</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6774</th>\n",
       "      <td>8528.0</td>\n",
       "      <td>0.447396</td>\n",
       "      <td>2.481954</td>\n",
       "      <td>-5.660814</td>\n",
       "      <td>4.455923</td>\n",
       "      <td>-2.443780</td>\n",
       "      <td>-2.185040</td>\n",
       "      <td>-4.716143</td>\n",
       "      <td>1.249803</td>\n",
       "      <td>-0.718326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.756053</td>\n",
       "      <td>0.140168</td>\n",
       "      <td>0.665411</td>\n",
       "      <td>0.131464</td>\n",
       "      <td>-1.908217</td>\n",
       "      <td>0.334808</td>\n",
       "      <td>0.748534</td>\n",
       "      <td>0.175414</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6820</th>\n",
       "      <td>8614.0</td>\n",
       "      <td>-2.169929</td>\n",
       "      <td>3.639654</td>\n",
       "      <td>-4.508498</td>\n",
       "      <td>2.730668</td>\n",
       "      <td>-2.122693</td>\n",
       "      <td>-2.341017</td>\n",
       "      <td>-4.235253</td>\n",
       "      <td>1.703538</td>\n",
       "      <td>-1.305279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645103</td>\n",
       "      <td>-0.503529</td>\n",
       "      <td>-0.000523</td>\n",
       "      <td>0.071696</td>\n",
       "      <td>0.092007</td>\n",
       "      <td>0.308498</td>\n",
       "      <td>0.552591</td>\n",
       "      <td>0.298954</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6870</th>\n",
       "      <td>8757.0</td>\n",
       "      <td>-1.863756</td>\n",
       "      <td>3.442644</td>\n",
       "      <td>-4.468260</td>\n",
       "      <td>2.805336</td>\n",
       "      <td>-2.118412</td>\n",
       "      <td>-2.332285</td>\n",
       "      <td>-4.261237</td>\n",
       "      <td>1.701682</td>\n",
       "      <td>-1.439396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.667927</td>\n",
       "      <td>-0.516242</td>\n",
       "      <td>-0.012218</td>\n",
       "      <td>0.070614</td>\n",
       "      <td>0.058504</td>\n",
       "      <td>0.304883</td>\n",
       "      <td>0.418012</td>\n",
       "      <td>0.208858</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6882</th>\n",
       "      <td>8808.0</td>\n",
       "      <td>-4.617217</td>\n",
       "      <td>1.695694</td>\n",
       "      <td>-3.114372</td>\n",
       "      <td>4.328199</td>\n",
       "      <td>-1.873257</td>\n",
       "      <td>-0.989908</td>\n",
       "      <td>-4.577265</td>\n",
       "      <td>0.472216</td>\n",
       "      <td>0.472017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.481830</td>\n",
       "      <td>0.146023</td>\n",
       "      <td>0.117039</td>\n",
       "      <td>-0.217565</td>\n",
       "      <td>-0.138776</td>\n",
       "      <td>-0.424453</td>\n",
       "      <td>-1.002041</td>\n",
       "      <td>0.890780</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6899</th>\n",
       "      <td>8878.0</td>\n",
       "      <td>-2.661802</td>\n",
       "      <td>5.856393</td>\n",
       "      <td>-7.653616</td>\n",
       "      <td>6.379742</td>\n",
       "      <td>-0.060712</td>\n",
       "      <td>-3.131550</td>\n",
       "      <td>-3.103570</td>\n",
       "      <td>1.778492</td>\n",
       "      <td>-3.831154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.734775</td>\n",
       "      <td>-0.435901</td>\n",
       "      <td>-0.384766</td>\n",
       "      <td>-0.286016</td>\n",
       "      <td>1.007934</td>\n",
       "      <td>0.413196</td>\n",
       "      <td>0.280284</td>\n",
       "      <td>0.303937</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6903</th>\n",
       "      <td>8886.0</td>\n",
       "      <td>-2.535852</td>\n",
       "      <td>5.793644</td>\n",
       "      <td>-7.618463</td>\n",
       "      <td>6.395830</td>\n",
       "      <td>-0.065210</td>\n",
       "      <td>-3.136372</td>\n",
       "      <td>-3.104557</td>\n",
       "      <td>1.823233</td>\n",
       "      <td>-3.878658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.716720</td>\n",
       "      <td>-0.448060</td>\n",
       "      <td>-0.402407</td>\n",
       "      <td>-0.288835</td>\n",
       "      <td>1.011752</td>\n",
       "      <td>0.425965</td>\n",
       "      <td>0.413140</td>\n",
       "      <td>0.308205</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6971</th>\n",
       "      <td>9064.0</td>\n",
       "      <td>-3.499108</td>\n",
       "      <td>0.258555</td>\n",
       "      <td>-4.489558</td>\n",
       "      <td>4.853894</td>\n",
       "      <td>-6.974522</td>\n",
       "      <td>3.628382</td>\n",
       "      <td>5.431271</td>\n",
       "      <td>-1.946734</td>\n",
       "      <td>-0.775680</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.052368</td>\n",
       "      <td>0.204817</td>\n",
       "      <td>-2.119007</td>\n",
       "      <td>0.170279</td>\n",
       "      <td>-0.393844</td>\n",
       "      <td>0.296367</td>\n",
       "      <td>1.985913</td>\n",
       "      <td>-0.900452</td>\n",
       "      <td>1809.68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8296</th>\n",
       "      <td>11080.0</td>\n",
       "      <td>-2.125490</td>\n",
       "      <td>5.973556</td>\n",
       "      <td>-11.034727</td>\n",
       "      <td>9.007147</td>\n",
       "      <td>-1.689451</td>\n",
       "      <td>-2.854415</td>\n",
       "      <td>-7.810441</td>\n",
       "      <td>2.030870</td>\n",
       "      <td>-5.902828</td>\n",
       "      <td>...</td>\n",
       "      <td>1.646518</td>\n",
       "      <td>-0.278485</td>\n",
       "      <td>-0.664841</td>\n",
       "      <td>-1.164555</td>\n",
       "      <td>1.701796</td>\n",
       "      <td>0.690806</td>\n",
       "      <td>2.119749</td>\n",
       "      <td>1.108933</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8312</th>\n",
       "      <td>11092.0</td>\n",
       "      <td>0.378275</td>\n",
       "      <td>3.914797</td>\n",
       "      <td>-5.726872</td>\n",
       "      <td>6.094141</td>\n",
       "      <td>1.698875</td>\n",
       "      <td>-2.807314</td>\n",
       "      <td>-0.591118</td>\n",
       "      <td>-0.123496</td>\n",
       "      <td>-2.530713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149896</td>\n",
       "      <td>-0.601967</td>\n",
       "      <td>-0.613724</td>\n",
       "      <td>-0.403114</td>\n",
       "      <td>1.568445</td>\n",
       "      <td>0.521884</td>\n",
       "      <td>0.527938</td>\n",
       "      <td>0.411910</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8335</th>\n",
       "      <td>11131.0</td>\n",
       "      <td>-1.426623</td>\n",
       "      <td>4.141986</td>\n",
       "      <td>-9.804103</td>\n",
       "      <td>6.666273</td>\n",
       "      <td>-4.749527</td>\n",
       "      <td>-2.073129</td>\n",
       "      <td>-10.089931</td>\n",
       "      <td>2.791345</td>\n",
       "      <td>-3.249516</td>\n",
       "      <td>...</td>\n",
       "      <td>1.865679</td>\n",
       "      <td>0.407809</td>\n",
       "      <td>0.605809</td>\n",
       "      <td>-0.769348</td>\n",
       "      <td>-1.746337</td>\n",
       "      <td>0.502040</td>\n",
       "      <td>1.977258</td>\n",
       "      <td>0.711607</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8615</th>\n",
       "      <td>11629.0</td>\n",
       "      <td>-3.891192</td>\n",
       "      <td>7.098916</td>\n",
       "      <td>-11.426467</td>\n",
       "      <td>8.607557</td>\n",
       "      <td>-2.065706</td>\n",
       "      <td>-2.985288</td>\n",
       "      <td>-8.138589</td>\n",
       "      <td>2.973928</td>\n",
       "      <td>-6.272790</td>\n",
       "      <td>...</td>\n",
       "      <td>1.757085</td>\n",
       "      <td>-0.189709</td>\n",
       "      <td>-0.508629</td>\n",
       "      <td>-1.189308</td>\n",
       "      <td>1.188536</td>\n",
       "      <td>0.605242</td>\n",
       "      <td>1.881529</td>\n",
       "      <td>0.875260</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8617</th>\n",
       "      <td>11635.0</td>\n",
       "      <td>0.919137</td>\n",
       "      <td>4.199633</td>\n",
       "      <td>-7.535607</td>\n",
       "      <td>7.426940</td>\n",
       "      <td>1.118215</td>\n",
       "      <td>-2.886722</td>\n",
       "      <td>-1.341036</td>\n",
       "      <td>0.363933</td>\n",
       "      <td>-2.203224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.316094</td>\n",
       "      <td>0.055179</td>\n",
       "      <td>0.210692</td>\n",
       "      <td>-0.417918</td>\n",
       "      <td>-0.911188</td>\n",
       "      <td>0.466524</td>\n",
       "      <td>0.627393</td>\n",
       "      <td>0.157851</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56795</th>\n",
       "      <td>47598.0</td>\n",
       "      <td>1.041691</td>\n",
       "      <td>0.134341</td>\n",
       "      <td>0.432002</td>\n",
       "      <td>1.309534</td>\n",
       "      <td>-0.580249</td>\n",
       "      <td>-1.232390</td>\n",
       "      <td>0.369524</td>\n",
       "      <td>-0.311498</td>\n",
       "      <td>-0.122135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118793</td>\n",
       "      <td>0.211002</td>\n",
       "      <td>-0.113269</td>\n",
       "      <td>0.945238</td>\n",
       "      <td>0.598161</td>\n",
       "      <td>-0.371825</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>0.041498</td>\n",
       "      <td>90.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284674</th>\n",
       "      <td>172670.0</td>\n",
       "      <td>1.939795</td>\n",
       "      <td>-0.969791</td>\n",
       "      <td>-0.587017</td>\n",
       "      <td>-1.309403</td>\n",
       "      <td>-1.126185</td>\n",
       "      <td>-0.986735</td>\n",
       "      <td>-0.619530</td>\n",
       "      <td>-0.143709</td>\n",
       "      <td>2.387882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285527</td>\n",
       "      <td>1.056616</td>\n",
       "      <td>0.023114</td>\n",
       "      <td>0.058599</td>\n",
       "      <td>-0.057562</td>\n",
       "      <td>-0.066172</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>-0.035789</td>\n",
       "      <td>59.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126321</th>\n",
       "      <td>77983.0</td>\n",
       "      <td>0.913972</td>\n",
       "      <td>-0.828388</td>\n",
       "      <td>1.092398</td>\n",
       "      <td>0.224209</td>\n",
       "      <td>-1.227345</td>\n",
       "      <td>0.302487</td>\n",
       "      <td>-0.745488</td>\n",
       "      <td>0.342838</td>\n",
       "      <td>1.033868</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.088401</td>\n",
       "      <td>-0.264313</td>\n",
       "      <td>0.041933</td>\n",
       "      <td>0.282237</td>\n",
       "      <td>-0.057726</td>\n",
       "      <td>0.934120</td>\n",
       "      <td>-0.044972</td>\n",
       "      <td>0.018795</td>\n",
       "      <td>110.12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89823</th>\n",
       "      <td>62738.0</td>\n",
       "      <td>-1.329611</td>\n",
       "      <td>1.436049</td>\n",
       "      <td>0.641393</td>\n",
       "      <td>0.765582</td>\n",
       "      <td>-0.403696</td>\n",
       "      <td>-0.347859</td>\n",
       "      <td>-0.230172</td>\n",
       "      <td>0.879833</td>\n",
       "      <td>-0.912176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174216</td>\n",
       "      <td>0.175966</td>\n",
       "      <td>0.059644</td>\n",
       "      <td>-0.038264</td>\n",
       "      <td>-0.204493</td>\n",
       "      <td>-0.423490</td>\n",
       "      <td>-0.334015</td>\n",
       "      <td>-0.018285</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188492</th>\n",
       "      <td>127997.0</td>\n",
       "      <td>-0.820699</td>\n",
       "      <td>-0.122397</td>\n",
       "      <td>0.861284</td>\n",
       "      <td>0.367451</td>\n",
       "      <td>-2.619773</td>\n",
       "      <td>1.867432</td>\n",
       "      <td>2.961182</td>\n",
       "      <td>-0.650173</td>\n",
       "      <td>0.171364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177583</td>\n",
       "      <td>0.992168</td>\n",
       "      <td>0.054760</td>\n",
       "      <td>0.810403</td>\n",
       "      <td>0.520799</td>\n",
       "      <td>-0.138601</td>\n",
       "      <td>0.133953</td>\n",
       "      <td>-0.267799</td>\n",
       "      <td>654.47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145649</th>\n",
       "      <td>87112.0</td>\n",
       "      <td>-1.385922</td>\n",
       "      <td>0.579174</td>\n",
       "      <td>2.131701</td>\n",
       "      <td>-2.708000</td>\n",
       "      <td>-0.926114</td>\n",
       "      <td>-0.347085</td>\n",
       "      <td>-0.279286</td>\n",
       "      <td>0.770581</td>\n",
       "      <td>0.544155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294970</td>\n",
       "      <td>0.714933</td>\n",
       "      <td>-0.305235</td>\n",
       "      <td>0.052438</td>\n",
       "      <td>0.383744</td>\n",
       "      <td>0.595801</td>\n",
       "      <td>0.092731</td>\n",
       "      <td>0.042493</td>\n",
       "      <td>24.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275397</th>\n",
       "      <td>166512.0</td>\n",
       "      <td>-1.353560</td>\n",
       "      <td>2.020940</td>\n",
       "      <td>-1.955259</td>\n",
       "      <td>-1.721515</td>\n",
       "      <td>1.355762</td>\n",
       "      <td>-0.651022</td>\n",
       "      <td>1.308958</td>\n",
       "      <td>0.081817</td>\n",
       "      <td>0.406266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067501</td>\n",
       "      <td>0.676354</td>\n",
       "      <td>-0.267574</td>\n",
       "      <td>-0.131928</td>\n",
       "      <td>0.028633</td>\n",
       "      <td>0.087206</td>\n",
       "      <td>0.619847</td>\n",
       "      <td>0.276327</td>\n",
       "      <td>4.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21752</th>\n",
       "      <td>31839.0</td>\n",
       "      <td>1.199514</td>\n",
       "      <td>-0.584223</td>\n",
       "      <td>0.491112</td>\n",
       "      <td>-0.863807</td>\n",
       "      <td>-0.894334</td>\n",
       "      <td>-0.311949</td>\n",
       "      <td>-0.564688</td>\n",
       "      <td>0.011751</td>\n",
       "      <td>1.926518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113982</td>\n",
       "      <td>0.482180</td>\n",
       "      <td>-0.282876</td>\n",
       "      <td>-0.418304</td>\n",
       "      <td>0.712144</td>\n",
       "      <td>-0.484165</td>\n",
       "      <td>0.082669</td>\n",
       "      <td>0.033683</td>\n",
       "      <td>56.40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255064</th>\n",
       "      <td>157049.0</td>\n",
       "      <td>2.039404</td>\n",
       "      <td>-1.002074</td>\n",
       "      <td>0.369398</td>\n",
       "      <td>-0.393281</td>\n",
       "      <td>-1.526485</td>\n",
       "      <td>-0.051694</td>\n",
       "      <td>-1.459913</td>\n",
       "      <td>0.070210</td>\n",
       "      <td>0.149020</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.092808</td>\n",
       "      <td>0.363541</td>\n",
       "      <td>0.402880</td>\n",
       "      <td>1.127248</td>\n",
       "      <td>-0.699631</td>\n",
       "      <td>0.554975</td>\n",
       "      <td>0.031814</td>\n",
       "      <td>-0.014916</td>\n",
       "      <td>16.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166328</th>\n",
       "      <td>118005.0</td>\n",
       "      <td>-1.081547</td>\n",
       "      <td>-0.629688</td>\n",
       "      <td>1.221623</td>\n",
       "      <td>-1.628422</td>\n",
       "      <td>-0.860295</td>\n",
       "      <td>0.244560</td>\n",
       "      <td>-0.509576</td>\n",
       "      <td>0.644884</td>\n",
       "      <td>-0.454387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141750</td>\n",
       "      <td>0.025494</td>\n",
       "      <td>0.193454</td>\n",
       "      <td>0.565466</td>\n",
       "      <td>-0.154862</td>\n",
       "      <td>-0.394144</td>\n",
       "      <td>-0.011036</td>\n",
       "      <td>0.024600</td>\n",
       "      <td>121.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112705</th>\n",
       "      <td>72770.0</td>\n",
       "      <td>0.506862</td>\n",
       "      <td>-0.922634</td>\n",
       "      <td>0.139899</td>\n",
       "      <td>1.591697</td>\n",
       "      <td>-0.616265</td>\n",
       "      <td>0.100695</td>\n",
       "      <td>0.293569</td>\n",
       "      <td>0.110966</td>\n",
       "      <td>0.179105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136388</td>\n",
       "      <td>-0.176260</td>\n",
       "      <td>-0.307623</td>\n",
       "      <td>0.212292</td>\n",
       "      <td>0.447291</td>\n",
       "      <td>-0.371003</td>\n",
       "      <td>-0.030770</td>\n",
       "      <td>0.059021</td>\n",
       "      <td>318.70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70287</th>\n",
       "      <td>53802.0</td>\n",
       "      <td>-0.828985</td>\n",
       "      <td>0.223099</td>\n",
       "      <td>1.197778</td>\n",
       "      <td>0.901558</td>\n",
       "      <td>1.389213</td>\n",
       "      <td>0.661813</td>\n",
       "      <td>0.127754</td>\n",
       "      <td>0.363056</td>\n",
       "      <td>-0.512125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013285</td>\n",
       "      <td>0.026479</td>\n",
       "      <td>-0.255748</td>\n",
       "      <td>-1.151049</td>\n",
       "      <td>0.251029</td>\n",
       "      <td>-0.190724</td>\n",
       "      <td>0.116266</td>\n",
       "      <td>0.103042</td>\n",
       "      <td>12.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218316</th>\n",
       "      <td>141264.0</td>\n",
       "      <td>-0.980695</td>\n",
       "      <td>0.608153</td>\n",
       "      <td>-0.795790</td>\n",
       "      <td>-0.274221</td>\n",
       "      <td>2.856355</td>\n",
       "      <td>1.132250</td>\n",
       "      <td>1.578232</td>\n",
       "      <td>0.120688</td>\n",
       "      <td>-0.579925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049555</td>\n",
       "      <td>0.455529</td>\n",
       "      <td>-0.118529</td>\n",
       "      <td>-1.105265</td>\n",
       "      <td>0.391706</td>\n",
       "      <td>-0.547424</td>\n",
       "      <td>-0.096189</td>\n",
       "      <td>-0.095819</td>\n",
       "      <td>60.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169103</th>\n",
       "      <td>119533.0</td>\n",
       "      <td>-1.101600</td>\n",
       "      <td>0.514214</td>\n",
       "      <td>-1.099052</td>\n",
       "      <td>-0.565095</td>\n",
       "      <td>2.598586</td>\n",
       "      <td>-1.811047</td>\n",
       "      <td>1.142124</td>\n",
       "      <td>-0.373841</td>\n",
       "      <td>-0.685443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080084</td>\n",
       "      <td>0.299715</td>\n",
       "      <td>-0.413857</td>\n",
       "      <td>0.451392</td>\n",
       "      <td>0.247661</td>\n",
       "      <td>0.619273</td>\n",
       "      <td>0.201494</td>\n",
       "      <td>0.276453</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71260</th>\n",
       "      <td>54231.0</td>\n",
       "      <td>1.285317</td>\n",
       "      <td>-1.231193</td>\n",
       "      <td>-0.517448</td>\n",
       "      <td>-1.620853</td>\n",
       "      <td>0.846638</td>\n",
       "      <td>3.785542</td>\n",
       "      <td>-1.639419</td>\n",
       "      <td>0.987404</td>\n",
       "      <td>-0.243874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294856</td>\n",
       "      <td>0.627961</td>\n",
       "      <td>-0.197691</td>\n",
       "      <td>1.060539</td>\n",
       "      <td>0.593793</td>\n",
       "      <td>-0.038359</td>\n",
       "      <td>0.040128</td>\n",
       "      <td>0.030423</td>\n",
       "      <td>76.06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92029</th>\n",
       "      <td>63737.0</td>\n",
       "      <td>-0.456099</td>\n",
       "      <td>-0.435059</td>\n",
       "      <td>1.782393</td>\n",
       "      <td>-1.905549</td>\n",
       "      <td>-1.588900</td>\n",
       "      <td>0.738140</td>\n",
       "      <td>-1.350579</td>\n",
       "      <td>0.784740</td>\n",
       "      <td>-2.138339</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051439</td>\n",
       "      <td>0.269702</td>\n",
       "      <td>0.005983</td>\n",
       "      <td>-0.294914</td>\n",
       "      <td>-0.182162</td>\n",
       "      <td>-0.203434</td>\n",
       "      <td>-0.009369</td>\n",
       "      <td>-0.039361</td>\n",
       "      <td>29.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80414</th>\n",
       "      <td>58474.0</td>\n",
       "      <td>-2.879534</td>\n",
       "      <td>-0.988527</td>\n",
       "      <td>0.088406</td>\n",
       "      <td>-0.631671</td>\n",
       "      <td>1.136279</td>\n",
       "      <td>-1.393598</td>\n",
       "      <td>0.159892</td>\n",
       "      <td>-0.383214</td>\n",
       "      <td>0.660847</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.116711</td>\n",
       "      <td>0.102830</td>\n",
       "      <td>-1.054873</td>\n",
       "      <td>0.162419</td>\n",
       "      <td>-0.821382</td>\n",
       "      <td>0.642570</td>\n",
       "      <td>-1.173817</td>\n",
       "      <td>-0.178995</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74968</th>\n",
       "      <td>55832.0</td>\n",
       "      <td>-1.136544</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>2.333673</td>\n",
       "      <td>-0.500471</td>\n",
       "      <td>0.211448</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.273395</td>\n",
       "      <td>0.061923</td>\n",
       "      <td>0.884416</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025105</td>\n",
       "      <td>0.585408</td>\n",
       "      <td>0.137101</td>\n",
       "      <td>-0.279624</td>\n",
       "      <td>-0.655624</td>\n",
       "      <td>0.073132</td>\n",
       "      <td>-0.276086</td>\n",
       "      <td>-0.247415</td>\n",
       "      <td>15.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176966</th>\n",
       "      <td>122984.0</td>\n",
       "      <td>-1.185658</td>\n",
       "      <td>0.950524</td>\n",
       "      <td>-0.328501</td>\n",
       "      <td>0.286813</td>\n",
       "      <td>-0.422294</td>\n",
       "      <td>0.100904</td>\n",
       "      <td>-0.785325</td>\n",
       "      <td>1.095475</td>\n",
       "      <td>0.251456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.381282</td>\n",
       "      <td>1.042544</td>\n",
       "      <td>-0.076831</td>\n",
       "      <td>0.646067</td>\n",
       "      <td>-0.385216</td>\n",
       "      <td>-0.105818</td>\n",
       "      <td>-0.069775</td>\n",
       "      <td>-0.022820</td>\n",
       "      <td>19.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159755</th>\n",
       "      <td>112892.0</td>\n",
       "      <td>-1.906818</td>\n",
       "      <td>2.478037</td>\n",
       "      <td>-1.868939</td>\n",
       "      <td>-0.392239</td>\n",
       "      <td>-0.859352</td>\n",
       "      <td>-1.446959</td>\n",
       "      <td>-0.433668</td>\n",
       "      <td>1.482814</td>\n",
       "      <td>-0.065735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450872</td>\n",
       "      <td>1.227698</td>\n",
       "      <td>0.128238</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>-0.567463</td>\n",
       "      <td>-0.192351</td>\n",
       "      <td>0.325972</td>\n",
       "      <td>0.251822</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15808</th>\n",
       "      <td>27252.0</td>\n",
       "      <td>-0.527136</td>\n",
       "      <td>0.948084</td>\n",
       "      <td>-0.695599</td>\n",
       "      <td>-1.126850</td>\n",
       "      <td>2.330580</td>\n",
       "      <td>3.222901</td>\n",
       "      <td>-0.107501</td>\n",
       "      <td>1.237228</td>\n",
       "      <td>-0.842058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112670</td>\n",
       "      <td>0.064719</td>\n",
       "      <td>-0.133956</td>\n",
       "      <td>1.037885</td>\n",
       "      <td>-0.189111</td>\n",
       "      <td>0.301833</td>\n",
       "      <td>-0.017194</td>\n",
       "      <td>0.081879</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247063</th>\n",
       "      <td>153443.0</td>\n",
       "      <td>-0.514697</td>\n",
       "      <td>0.527294</td>\n",
       "      <td>0.606928</td>\n",
       "      <td>0.080586</td>\n",
       "      <td>0.701425</td>\n",
       "      <td>-0.942797</td>\n",
       "      <td>0.870933</td>\n",
       "      <td>-0.273695</td>\n",
       "      <td>-0.389845</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.214289</td>\n",
       "      <td>-0.428345</td>\n",
       "      <td>0.338046</td>\n",
       "      <td>-0.099375</td>\n",
       "      <td>-0.519953</td>\n",
       "      <td>0.335911</td>\n",
       "      <td>0.039609</td>\n",
       "      <td>0.116154</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228201</th>\n",
       "      <td>145399.0</td>\n",
       "      <td>-2.217708</td>\n",
       "      <td>-0.194399</td>\n",
       "      <td>-0.048710</td>\n",
       "      <td>-0.447199</td>\n",
       "      <td>1.159174</td>\n",
       "      <td>-0.786004</td>\n",
       "      <td>1.159495</td>\n",
       "      <td>0.150086</td>\n",
       "      <td>-0.579640</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085498</td>\n",
       "      <td>-0.354979</td>\n",
       "      <td>0.198817</td>\n",
       "      <td>0.475738</td>\n",
       "      <td>1.184783</td>\n",
       "      <td>-0.254685</td>\n",
       "      <td>-0.150517</td>\n",
       "      <td>-0.113326</td>\n",
       "      <td>135.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98043</th>\n",
       "      <td>66492.0</td>\n",
       "      <td>-0.280433</td>\n",
       "      <td>1.118244</td>\n",
       "      <td>1.692624</td>\n",
       "      <td>1.272075</td>\n",
       "      <td>0.133880</td>\n",
       "      <td>-0.691412</td>\n",
       "      <td>0.848896</td>\n",
       "      <td>-0.264691</td>\n",
       "      <td>-0.155941</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.244353</td>\n",
       "      <td>-0.329981</td>\n",
       "      <td>-0.126164</td>\n",
       "      <td>0.597074</td>\n",
       "      <td>-0.254092</td>\n",
       "      <td>-0.537751</td>\n",
       "      <td>0.020416</td>\n",
       "      <td>-0.049995</td>\n",
       "      <td>5.46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254118</th>\n",
       "      <td>156588.0</td>\n",
       "      <td>-0.335919</td>\n",
       "      <td>0.856781</td>\n",
       "      <td>-1.250188</td>\n",
       "      <td>-1.824806</td>\n",
       "      <td>0.047590</td>\n",
       "      <td>-0.496408</td>\n",
       "      <td>-0.145478</td>\n",
       "      <td>0.491390</td>\n",
       "      <td>-1.719179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661432</td>\n",
       "      <td>1.668454</td>\n",
       "      <td>-0.098150</td>\n",
       "      <td>0.135267</td>\n",
       "      <td>-0.709367</td>\n",
       "      <td>-0.061905</td>\n",
       "      <td>-0.128741</td>\n",
       "      <td>0.123834</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55930</th>\n",
       "      <td>47192.0</td>\n",
       "      <td>-1.086622</td>\n",
       "      <td>-0.831648</td>\n",
       "      <td>1.749068</td>\n",
       "      <td>-1.850870</td>\n",
       "      <td>0.016826</td>\n",
       "      <td>-0.196467</td>\n",
       "      <td>0.021741</td>\n",
       "      <td>0.160210</td>\n",
       "      <td>-1.002623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125497</td>\n",
       "      <td>0.031394</td>\n",
       "      <td>0.224030</td>\n",
       "      <td>-0.383501</td>\n",
       "      <td>-0.137196</td>\n",
       "      <td>-0.541747</td>\n",
       "      <td>0.109225</td>\n",
       "      <td>-0.052564</td>\n",
       "      <td>113.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8469</th>\n",
       "      <td>11349.0</td>\n",
       "      <td>-0.471906</td>\n",
       "      <td>0.411932</td>\n",
       "      <td>1.951918</td>\n",
       "      <td>1.482344</td>\n",
       "      <td>0.610217</td>\n",
       "      <td>0.021270</td>\n",
       "      <td>0.261656</td>\n",
       "      <td>-0.113203</td>\n",
       "      <td>1.408417</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.078171</td>\n",
       "      <td>0.355041</td>\n",
       "      <td>-0.097925</td>\n",
       "      <td>0.036685</td>\n",
       "      <td>-0.326912</td>\n",
       "      <td>-0.313997</td>\n",
       "      <td>0.006723</td>\n",
       "      <td>-0.060625</td>\n",
       "      <td>9.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3745</th>\n",
       "      <td>3233.0</td>\n",
       "      <td>-2.315265</td>\n",
       "      <td>2.052292</td>\n",
       "      <td>0.249270</td>\n",
       "      <td>-1.794818</td>\n",
       "      <td>-0.569477</td>\n",
       "      <td>-0.288018</td>\n",
       "      <td>-0.113963</td>\n",
       "      <td>0.799518</td>\n",
       "      <td>1.110210</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.221714</td>\n",
       "      <td>-0.301018</td>\n",
       "      <td>0.107997</td>\n",
       "      <td>-0.313137</td>\n",
       "      <td>0.054482</td>\n",
       "      <td>0.792139</td>\n",
       "      <td>0.797767</td>\n",
       "      <td>0.407600</td>\n",
       "      <td>3.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7793</th>\n",
       "      <td>10849.0</td>\n",
       "      <td>-0.954087</td>\n",
       "      <td>0.955532</td>\n",
       "      <td>2.300461</td>\n",
       "      <td>2.914967</td>\n",
       "      <td>-0.747344</td>\n",
       "      <td>0.970495</td>\n",
       "      <td>-0.316617</td>\n",
       "      <td>0.744130</td>\n",
       "      <td>0.570931</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009375</td>\n",
       "      <td>0.066509</td>\n",
       "      <td>0.207826</td>\n",
       "      <td>-0.025413</td>\n",
       "      <td>-0.496521</td>\n",
       "      <td>0.036668</td>\n",
       "      <td>0.009455</td>\n",
       "      <td>0.072228</td>\n",
       "      <td>90.55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6419</th>\n",
       "      <td>7605.0</td>\n",
       "      <td>0.823033</td>\n",
       "      <td>-0.650987</td>\n",
       "      <td>-0.342745</td>\n",
       "      <td>0.147452</td>\n",
       "      <td>-0.377368</td>\n",
       "      <td>-0.815667</td>\n",
       "      <td>0.411074</td>\n",
       "      <td>-0.247525</td>\n",
       "      <td>1.204486</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.373251</td>\n",
       "      <td>-1.532985</td>\n",
       "      <td>-0.089402</td>\n",
       "      <td>-0.063473</td>\n",
       "      <td>0.050302</td>\n",
       "      <td>0.679952</td>\n",
       "      <td>-0.197568</td>\n",
       "      <td>0.018242</td>\n",
       "      <td>252.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>984 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2         V3        V4        V5        V6  \\\n",
       "541        406.0 -2.312227  1.951992  -1.609851  3.997906 -0.522188 -1.426545   \n",
       "623        472.0 -3.043541 -3.157307   1.088463  2.288644  1.359805 -1.064823   \n",
       "4920      4462.0 -2.303350  1.759247  -0.359745  2.330243 -0.821628 -0.075788   \n",
       "6108      6986.0 -4.397974  1.358367  -2.592844  2.679787 -1.128131 -1.706536   \n",
       "6329      7519.0  1.234235  3.019740  -4.304597  4.732795  3.624201 -1.357746   \n",
       "6331      7526.0  0.008430  4.137837  -6.240697  6.675732  0.768307 -3.353060   \n",
       "6334      7535.0  0.026779  4.132464  -6.560600  6.348557  1.329666 -2.513479   \n",
       "6336      7543.0  0.329594  3.712889  -5.775935  6.078266  1.667359 -2.420168   \n",
       "6338      7551.0  0.316459  3.809076  -5.615159  6.047445  1.554026 -2.651353   \n",
       "6427      7610.0  0.725646  2.300894  -5.329976  4.007683 -1.730411 -1.732193   \n",
       "6446      7672.0  0.702710  2.426433  -5.234513  4.416661 -2.170806 -2.667554   \n",
       "6472      7740.0  1.023874  2.001485  -4.769752  3.819195 -1.271754 -1.734662   \n",
       "6529      7891.0 -1.585505  3.261585  -4.137422  2.357096 -1.405043 -1.879437   \n",
       "6609      8090.0 -1.783229  3.402794  -3.822742  2.625368 -1.976415 -2.731689   \n",
       "6641      8169.0  0.857321  4.093912  -7.423894  7.380245  0.973366 -2.730762   \n",
       "6717      8408.0 -1.813280  4.917851  -5.926130  5.701500  1.204393 -3.035138   \n",
       "6719      8415.0 -0.251471  4.313523  -6.891438  6.796797  0.616297 -2.966327   \n",
       "6734      8451.0  0.314597  2.660670  -5.920037  4.522500 -2.315027 -2.278352   \n",
       "6774      8528.0  0.447396  2.481954  -5.660814  4.455923 -2.443780 -2.185040   \n",
       "6820      8614.0 -2.169929  3.639654  -4.508498  2.730668 -2.122693 -2.341017   \n",
       "6870      8757.0 -1.863756  3.442644  -4.468260  2.805336 -2.118412 -2.332285   \n",
       "6882      8808.0 -4.617217  1.695694  -3.114372  4.328199 -1.873257 -0.989908   \n",
       "6899      8878.0 -2.661802  5.856393  -7.653616  6.379742 -0.060712 -3.131550   \n",
       "6903      8886.0 -2.535852  5.793644  -7.618463  6.395830 -0.065210 -3.136372   \n",
       "6971      9064.0 -3.499108  0.258555  -4.489558  4.853894 -6.974522  3.628382   \n",
       "8296     11080.0 -2.125490  5.973556 -11.034727  9.007147 -1.689451 -2.854415   \n",
       "8312     11092.0  0.378275  3.914797  -5.726872  6.094141  1.698875 -2.807314   \n",
       "8335     11131.0 -1.426623  4.141986  -9.804103  6.666273 -4.749527 -2.073129   \n",
       "8615     11629.0 -3.891192  7.098916 -11.426467  8.607557 -2.065706 -2.985288   \n",
       "8617     11635.0  0.919137  4.199633  -7.535607  7.426940  1.118215 -2.886722   \n",
       "...          ...       ...       ...        ...       ...       ...       ...   \n",
       "56795    47598.0  1.041691  0.134341   0.432002  1.309534 -0.580249 -1.232390   \n",
       "284674  172670.0  1.939795 -0.969791  -0.587017 -1.309403 -1.126185 -0.986735   \n",
       "126321   77983.0  0.913972 -0.828388   1.092398  0.224209 -1.227345  0.302487   \n",
       "89823    62738.0 -1.329611  1.436049   0.641393  0.765582 -0.403696 -0.347859   \n",
       "188492  127997.0 -0.820699 -0.122397   0.861284  0.367451 -2.619773  1.867432   \n",
       "145649   87112.0 -1.385922  0.579174   2.131701 -2.708000 -0.926114 -0.347085   \n",
       "275397  166512.0 -1.353560  2.020940  -1.955259 -1.721515  1.355762 -0.651022   \n",
       "21752    31839.0  1.199514 -0.584223   0.491112 -0.863807 -0.894334 -0.311949   \n",
       "255064  157049.0  2.039404 -1.002074   0.369398 -0.393281 -1.526485 -0.051694   \n",
       "166328  118005.0 -1.081547 -0.629688   1.221623 -1.628422 -0.860295  0.244560   \n",
       "112705   72770.0  0.506862 -0.922634   0.139899  1.591697 -0.616265  0.100695   \n",
       "70287    53802.0 -0.828985  0.223099   1.197778  0.901558  1.389213  0.661813   \n",
       "218316  141264.0 -0.980695  0.608153  -0.795790 -0.274221  2.856355  1.132250   \n",
       "169103  119533.0 -1.101600  0.514214  -1.099052 -0.565095  2.598586 -1.811047   \n",
       "71260    54231.0  1.285317 -1.231193  -0.517448 -1.620853  0.846638  3.785542   \n",
       "92029    63737.0 -0.456099 -0.435059   1.782393 -1.905549 -1.588900  0.738140   \n",
       "80414    58474.0 -2.879534 -0.988527   0.088406 -0.631671  1.136279 -1.393598   \n",
       "74968    55832.0 -1.136544  0.187169   2.333673 -0.500471  0.211448  0.910448   \n",
       "176966  122984.0 -1.185658  0.950524  -0.328501  0.286813 -0.422294  0.100904   \n",
       "159755  112892.0 -1.906818  2.478037  -1.868939 -0.392239 -0.859352 -1.446959   \n",
       "15808    27252.0 -0.527136  0.948084  -0.695599 -1.126850  2.330580  3.222901   \n",
       "247063  153443.0 -0.514697  0.527294   0.606928  0.080586  0.701425 -0.942797   \n",
       "228201  145399.0 -2.217708 -0.194399  -0.048710 -0.447199  1.159174 -0.786004   \n",
       "98043    66492.0 -0.280433  1.118244   1.692624  1.272075  0.133880 -0.691412   \n",
       "254118  156588.0 -0.335919  0.856781  -1.250188 -1.824806  0.047590 -0.496408   \n",
       "55930    47192.0 -1.086622 -0.831648   1.749068 -1.850870  0.016826 -0.196467   \n",
       "8469     11349.0 -0.471906  0.411932   1.951918  1.482344  0.610217  0.021270   \n",
       "3745      3233.0 -2.315265  2.052292   0.249270 -1.794818 -0.569477 -0.288018   \n",
       "7793     10849.0 -0.954087  0.955532   2.300461  2.914967 -0.747344  0.970495   \n",
       "6419      7605.0  0.823033 -0.650987  -0.342745  0.147452 -0.377368 -0.815667   \n",
       "\n",
       "               V7        V8        V9  ...         V21       V22       V23  \\\n",
       "541     -2.537387  1.391657 -2.770089  ...    0.517232 -0.035049 -0.465211   \n",
       "623      0.325574 -0.067794 -0.270953  ...    0.661696  0.435477  1.375966   \n",
       "4920     0.562320 -0.399147 -0.238253  ...   -0.294166 -0.932391  0.172726   \n",
       "6108    -3.496197 -0.248778 -0.247768  ...    0.573574  0.176968 -0.436207   \n",
       "6329     1.713445 -0.496358 -1.282858  ...   -0.379068 -0.704181 -0.656805   \n",
       "6331    -1.631735  0.154612 -2.795892  ...    0.364514 -0.608057 -0.539528   \n",
       "6334    -1.689102  0.303253 -3.139409  ...    0.370509 -0.576752 -0.669605   \n",
       "6336    -0.812891  0.133080 -2.214311  ...    0.156617 -0.652450 -0.551572   \n",
       "6338    -0.746579  0.055586 -2.678679  ...    0.208828 -0.511747 -0.583813   \n",
       "6427    -3.968593  1.063728 -0.486097  ...    0.589669  0.109541  0.601045   \n",
       "6446    -3.878088  0.911337 -0.166199  ...    0.551180 -0.009802  0.721698   \n",
       "6472    -3.059245  0.889805  0.415382  ...    0.343283 -0.054196  0.709654   \n",
       "6529    -3.513687  1.515607 -1.207166  ...    0.501543 -0.546869 -0.076584   \n",
       "6609    -3.430559  1.413204 -0.776941  ...    0.454032 -0.577526  0.045967   \n",
       "6641    -1.496497  0.543015 -2.351190  ...    0.375026  0.145400  0.240603   \n",
       "6717    -1.713402  0.561257 -3.796354  ...    0.615642 -0.406427 -0.737018   \n",
       "6719    -2.436653  0.489328 -3.371639  ...    0.536892 -0.546126 -0.605240   \n",
       "6734    -4.684054  1.202270 -0.694696  ...    0.743314  0.064038  0.677842   \n",
       "6774    -4.716143  1.249803 -0.718326  ...    0.756053  0.140168  0.665411   \n",
       "6820    -4.235253  1.703538 -1.305279  ...    0.645103 -0.503529 -0.000523   \n",
       "6870    -4.261237  1.701682 -1.439396  ...    0.667927 -0.516242 -0.012218   \n",
       "6882    -4.577265  0.472216  0.472017  ...    0.481830  0.146023  0.117039   \n",
       "6899    -3.103570  1.778492 -3.831154  ...    0.734775 -0.435901 -0.384766   \n",
       "6903    -3.104557  1.823233 -3.878658  ...    0.716720 -0.448060 -0.402407   \n",
       "6971     5.431271 -1.946734 -0.775680  ...   -1.052368  0.204817 -2.119007   \n",
       "8296    -7.810441  2.030870 -5.902828  ...    1.646518 -0.278485 -0.664841   \n",
       "8312    -0.591118 -0.123496 -2.530713  ...    0.149896 -0.601967 -0.613724   \n",
       "8335   -10.089931  2.791345 -3.249516  ...    1.865679  0.407809  0.605809   \n",
       "8615    -8.138589  2.973928 -6.272790  ...    1.757085 -0.189709 -0.508629   \n",
       "8617    -1.341036  0.363933 -2.203224  ...    0.316094  0.055179  0.210692   \n",
       "...           ...       ...       ...  ...         ...       ...       ...   \n",
       "56795    0.369524 -0.311498 -0.122135  ...    0.118793  0.211002 -0.113269   \n",
       "284674  -0.619530 -0.143709  2.387882  ...    0.285527  1.056616  0.023114   \n",
       "126321  -0.745488  0.342838  1.033868  ...   -0.088401 -0.264313  0.041933   \n",
       "89823   -0.230172  0.879833 -0.912176  ...    0.174216  0.175966  0.059644   \n",
       "188492   2.961182 -0.650173  0.171364  ...    0.177583  0.992168  0.054760   \n",
       "145649  -0.279286  0.770581  0.544155  ...    0.294970  0.714933 -0.305235   \n",
       "275397   1.308958  0.081817  0.406266  ...    0.067501  0.676354 -0.267574   \n",
       "21752   -0.564688  0.011751  1.926518  ...    0.113982  0.482180 -0.282876   \n",
       "255064  -1.459913  0.070210  0.149020  ...   -0.092808  0.363541  0.402880   \n",
       "166328  -0.509576  0.644884 -0.454387  ...    0.141750  0.025494  0.193454   \n",
       "112705   0.293569  0.110966  0.179105  ...    0.136388 -0.176260 -0.307623   \n",
       "70287    0.127754  0.363056 -0.512125  ...    0.013285  0.026479 -0.255748   \n",
       "218316   1.578232  0.120688 -0.579925  ...    0.049555  0.455529 -0.118529   \n",
       "169103   1.142124 -0.373841 -0.685443  ...    0.080084  0.299715 -0.413857   \n",
       "71260   -1.639419  0.987404 -0.243874  ...    0.294856  0.627961 -0.197691   \n",
       "92029   -1.350579  0.784740 -2.138339  ...   -0.051439  0.269702  0.005983   \n",
       "80414    0.159892 -0.383214  0.660847  ...   -0.116711  0.102830 -1.054873   \n",
       "74968    0.273395  0.061923  0.884416  ...   -0.025105  0.585408  0.137101   \n",
       "176966  -0.785325  1.095475  0.251456  ...    0.381282  1.042544 -0.076831   \n",
       "159755  -0.433668  1.482814 -0.065735  ...    0.450872  1.227698  0.128238   \n",
       "15808   -0.107501  1.237228 -0.842058  ...    0.112670  0.064719 -0.133956   \n",
       "247063   0.870933 -0.273695 -0.389845  ...   -0.214289 -0.428345  0.338046   \n",
       "228201   1.159495  0.150086 -0.579640  ...   -0.085498 -0.354979  0.198817   \n",
       "98043    0.848896 -0.264691 -0.155941  ...   -0.244353 -0.329981 -0.126164   \n",
       "254118  -0.145478  0.491390 -1.719179  ...    0.661432  1.668454 -0.098150   \n",
       "55930    0.021741  0.160210 -1.002623  ...    0.125497  0.031394  0.224030   \n",
       "8469     0.261656 -0.113203  1.408417  ...   -0.078171  0.355041 -0.097925   \n",
       "3745    -0.113963  0.799518  1.110210  ...   -0.221714 -0.301018  0.107997   \n",
       "7793    -0.316617  0.744130  0.570931  ...   -0.009375  0.066509  0.207826   \n",
       "6419     0.411074 -0.247525  1.204486  ...   -0.373251 -1.532985 -0.089402   \n",
       "\n",
       "             V24       V25       V26       V27       V28   Amount  Class  \n",
       "541     0.320198  0.044519  0.177840  0.261145 -0.143276     0.00      1  \n",
       "623    -0.293803  0.279798 -0.145362 -0.252773  0.035764   529.00      1  \n",
       "4920   -0.087330 -0.156114 -0.542628  0.039566 -0.153029   239.93      1  \n",
       "6108   -0.053502  0.252405 -0.657488 -0.827136  0.849573    59.00      1  \n",
       "6329   -1.632653  1.488901  0.566797 -0.010016  0.146793     1.00      1  \n",
       "6331    0.128940  1.488481  0.507963  0.735822  0.513574     1.00      1  \n",
       "6334   -0.759908  1.605056  0.540675  0.737040  0.496699     1.00      1  \n",
       "6336   -0.716522  1.415717  0.555265  0.530507  0.404474     1.00      1  \n",
       "6338   -0.219845  1.474753  0.491192  0.518868  0.402528     1.00      1  \n",
       "6427   -0.364700 -1.843078  0.351909  0.594550  0.099372     1.00      1  \n",
       "6446    0.473246 -1.959304  0.319476  0.600485  0.129305     1.00      1  \n",
       "6472   -0.372216 -2.032068  0.366778  0.395171  0.020206     1.00      1  \n",
       "6529   -0.425550  0.123644  0.321985  0.264028  0.132817     1.00      1  \n",
       "6609    0.461700  0.044146  0.305704  0.530981  0.243746     1.00      1  \n",
       "6641   -0.234649 -1.004881  0.435832  0.618324  0.148469     1.00      1  \n",
       "6717   -0.279642  1.106766  0.323885  0.894767  0.569519     1.00      1  \n",
       "6719   -0.263743  1.539916  0.523574  0.891025  0.572741     1.00      1  \n",
       "6734    0.083008 -1.911034  0.322188  0.620867  0.185030     1.00      1  \n",
       "6774    0.131464 -1.908217  0.334808  0.748534  0.175414     1.00      1  \n",
       "6820    0.071696  0.092007  0.308498  0.552591  0.298954     1.00      1  \n",
       "6870    0.070614  0.058504  0.304883  0.418012  0.208858     1.00      1  \n",
       "6882   -0.217565 -0.138776 -0.424453 -1.002041  0.890780     1.10      1  \n",
       "6899   -0.286016  1.007934  0.413196  0.280284  0.303937     1.00      1  \n",
       "6903   -0.288835  1.011752  0.425965  0.413140  0.308205     1.00      1  \n",
       "6971    0.170279 -0.393844  0.296367  1.985913 -0.900452  1809.68      1  \n",
       "8296   -1.164555  1.701796  0.690806  2.119749  1.108933     1.00      1  \n",
       "8312   -0.403114  1.568445  0.521884  0.527938  0.411910     1.00      1  \n",
       "8335   -0.769348 -1.746337  0.502040  1.977258  0.711607     1.00      1  \n",
       "8615   -1.189308  1.188536  0.605242  1.881529  0.875260     1.00      1  \n",
       "8617   -0.417918 -0.911188  0.466524  0.627393  0.157851     1.00      1  \n",
       "...          ...       ...       ...       ...       ...      ...    ...  \n",
       "56795   0.945238  0.598161 -0.371825  0.000770  0.041498    90.00      0  \n",
       "284674  0.058599 -0.057562 -0.066172  0.031900 -0.035789    59.85      0  \n",
       "126321  0.282237 -0.057726  0.934120 -0.044972  0.018795   110.12      0  \n",
       "89823  -0.038264 -0.204493 -0.423490 -0.334015 -0.018285     2.50      0  \n",
       "188492  0.810403  0.520799 -0.138601  0.133953 -0.267799   654.47      0  \n",
       "145649  0.052438  0.383744  0.595801  0.092731  0.042493    24.90      0  \n",
       "275397 -0.131928  0.028633  0.087206  0.619847  0.276327     4.85      0  \n",
       "21752  -0.418304  0.712144 -0.484165  0.082669  0.033683    56.40      0  \n",
       "255064  1.127248 -0.699631  0.554975  0.031814 -0.014916    16.96      0  \n",
       "166328  0.565466 -0.154862 -0.394144 -0.011036  0.024600   121.10      0  \n",
       "112705  0.212292  0.447291 -0.371003 -0.030770  0.059021   318.70      0  \n",
       "70287  -1.151049  0.251029 -0.190724  0.116266  0.103042    12.97      0  \n",
       "218316 -1.105265  0.391706 -0.547424 -0.096189 -0.095819    60.60      0  \n",
       "169103  0.451392  0.247661  0.619273  0.201494  0.276453    15.00      0  \n",
       "71260   1.060539  0.593793 -0.038359  0.040128  0.030423    76.06      0  \n",
       "92029  -0.294914 -0.182162 -0.203434 -0.009369 -0.039361    29.00      0  \n",
       "80414   0.162419 -0.821382  0.642570 -1.173817 -0.178995     2.00      0  \n",
       "74968  -0.279624 -0.655624  0.073132 -0.276086 -0.247415    15.78      0  \n",
       "176966  0.646067 -0.385216 -0.105818 -0.069775 -0.022820    19.95      0  \n",
       "159755  0.001487 -0.567463 -0.192351  0.325972  0.251822     2.69      0  \n",
       "15808   1.037885 -0.189111  0.301833 -0.017194  0.081879     1.50      0  \n",
       "247063 -0.099375 -0.519953  0.335911  0.039609  0.116154     0.99      0  \n",
       "228201  0.475738  1.184783 -0.254685 -0.150517 -0.113326   135.58      0  \n",
       "98043   0.597074 -0.254092 -0.537751  0.020416 -0.049995     5.46      0  \n",
       "254118  0.135267 -0.709367 -0.061905 -0.128741  0.123834    15.00      0  \n",
       "55930  -0.383501 -0.137196 -0.541747  0.109225 -0.052564   113.00      0  \n",
       "8469    0.036685 -0.326912 -0.313997  0.006723 -0.060625     9.99      0  \n",
       "3745   -0.313137  0.054482  0.792139  0.797767  0.407600     3.80      0  \n",
       "7793   -0.025413 -0.496521  0.036668  0.009455  0.072228    90.55      0  \n",
       "6419   -0.063473  0.050302  0.679952 -0.197568  0.018242   252.90      0  \n",
       "\n",
       "[984 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "under_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLITTING THE DATASET INTO TRAIN AND TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_under = under_sample.loc[:,under_sample.columns != 'Class']\n",
    "y_under = under_sample.loc[:,under_sample.columns == 'Class']\n",
    "X_under_train, X_under_test, y_under_train, y_under_test = train_test_split(X_under,y_under,test_size = 0.3, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFE ON SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features: 15\n",
      "Selected features: [False False  True False  True False False  True  True False  True  True\n",
      "  True False  True False  True  True  True False  True False False  True\n",
      " False False False  True  True False]\n",
      "Ranking of features: [16  4  1 12  1 14 11  1  1  8  1  1  1  5  1  6  1  1  1  2  1 13  7  1\n",
      "  9  3 10  1  1 15]\n"
     ]
    }
   ],
   "source": [
    "model = SVC(kernel='linear')\n",
    "rfe = RFE(model)\n",
    "fit = rfe.fit(X_under_train,y_under_train)\n",
    "print(\"Number of Features: %d\"% fit.n_features_)\n",
    "print(\"Selected features: %s\"% fit.support_)\n",
    "print(\"Ranking of features: %s\"% fit.ranking_)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL FITTING ON TRAIN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[337   6]\n",
      " [ 34 311]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.98      0.94       343\n",
      "          1       0.98      0.90      0.94       345\n",
      "\n",
      "avg / total       0.94      0.94      0.94       688\n",
      "\n",
      "0.9418604651162791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "svclassifier = SVC(kernel='linear')  \n",
    "X = X_under_train[['V4','V6','V8','V9','V10','V11','V12','V14','V16','V17','V18','V21','V22','V23','V27']]\n",
    "svclassifier.fit(X, y_under_train)\n",
    "y_pred = svclassifier.predict(X)\n",
    "print(confusion_matrix(y_under_train,y_pred))  \n",
    "print(classification_report(y_under_train,y_pred))  \n",
    "print(accuracy_score(y_under_train, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL FITTING ON TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[149   0]\n",
      " [ 16 131]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95       149\n",
      "          1       1.00      0.89      0.94       147\n",
      "\n",
      "avg / total       0.95      0.95      0.95       296\n",
      "\n",
      "0.9459459459459459\n"
     ]
    }
   ],
   "source": [
    "X2 = X_under_test[['V4','V6','V8','V9','V10','V11','V12','V14','V16','V17','V18','V21','V22','V23','V27']]\n",
    "y_pred = svclassifier.predict(X2)\n",
    "print(confusion_matrix(y_under_test,y_pred))  \n",
    "print(classification_report(y_under_test,y_pred))  \n",
    "print(accuracy_score(y_under_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRIDSEARCH ON TRAIN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logreg__C': 10.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9433139534883721"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "logregpipe = Pipeline([('scale', StandardScaler()),\n",
    "                   ('logreg',LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\"))])\n",
    "\n",
    "# Gridsearch to determine the value of C\n",
    "param_grid = {'logreg__C':np.arange(0.01,100,10)}\n",
    "logreg_cv = GridSearchCV(logregpipe,param_grid,cv=5,return_train_score=True)\n",
    "logreg_cv.fit(X,y_under_train)\n",
    "print(logreg_cv.best_params_)\n",
    "\n",
    "bestlogreg = logreg_cv.best_estimator_\n",
    "bestlogreg.fit(X,y_under_train)\n",
    "bestlogreg.coef_ = bestlogreg.named_steps['logreg'].coef_\n",
    "bestlogreg.score(X,y_under_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRIDSEARCH ON TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9662162162162162"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestlogreg = logreg_cv.best_estimator_\n",
    "bestlogreg.fit(X2,y_under_test)\n",
    "bestlogreg.coef_ = bestlogreg.named_steps['logreg'].coef_\n",
    "bestlogreg.score(X2,y_under_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROSS VALIDATION ON TRAIN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-b7317f369fa1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_val_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_under_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_under_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[1;34m(estimator, X, y, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m   1374\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1376\u001b[1;33m     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1377\u001b[0m     \u001b[1;31m# We clone the estimator to make sure that all the folds are\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1378\u001b[0m     \u001b[1;31m# independent, and that it is pickle-able.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36mcheck_cv\u001b[1;34m(cv, X, y, classifier)\u001b[0m\n\u001b[0;32m   1833\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1834\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'binary'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'multiclass'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1835\u001b[1;33m                 \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1836\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1837\u001b[0m                 \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, y, n_folds, shuffle, random_state)\u001b[0m\n\u001b[0;32m    568\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtest_fold_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mper_label_splits\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mper_label_cvs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_split\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mper_label_splits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m                 \u001b[0mlabel_test_folds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_folds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m                 \u001b[1;31m# the test split can be too big because we used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m                 \u001b[1;31m# KFold(max(c, self.n_folds), self.n_folds) instead of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import cross_validation\n",
    "\n",
    "predicted = cross_validation.cross_val_predict(LogisticRegression(),X,y_under_train, cv=10)\n",
    "print (metrics.accuracy_score(y_under_train, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROSS VALIDATION ON TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-b3d9a5d1e3bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredicted1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_val_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_under_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_under_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_under_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[1;34m(estimator, X, y, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m   1374\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1376\u001b[1;33m     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1377\u001b[0m     \u001b[1;31m# We clone the estimator to make sure that all the folds are\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1378\u001b[0m     \u001b[1;31m# independent, and that it is pickle-able.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36mcheck_cv\u001b[1;34m(cv, X, y, classifier)\u001b[0m\n\u001b[0;32m   1833\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1834\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'binary'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'multiclass'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1835\u001b[1;33m                 \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1836\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1837\u001b[0m                 \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, y, n_folds, shuffle, random_state)\u001b[0m\n\u001b[0;32m    568\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtest_fold_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mper_label_splits\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mper_label_cvs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_split\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mper_label_splits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m                 \u001b[0mlabel_test_folds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_folds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m                 \u001b[1;31m# the test split can be too big because we used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m                 \u001b[1;31m# KFold(max(c, self.n_folds), self.n_folds) instead of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "predicted1 = cross_validation.cross_val_predict(LogisticRegression(),X2, y_under_test, cv=10)\n",
    "\n",
    "print (metrics.classification_report(y_under_test, predicted1))\n",
    "print (metrics.accuracy_score(y_under_test, predicted1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K BEST ON SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "array = under_sample.values\n",
    "test = SelectKBest(score_func=f_classif, k=10)\n",
    "fit = test.fit(X_under_train, y_under_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores_: [1.84895390e+01 1.65226628e+02 2.17034348e+02 3.29096028e+02\n",
      " 6.98210040e+02 1.14579626e+02 1.30717079e+02 2.32664021e+02\n",
      " 4.51207027e+00 2.77886598e+02 5.03044892e+02 6.27927314e+02\n",
      " 6.06978629e+02 5.65116604e-01 8.93102516e+02 9.46858536e-01\n",
      " 3.89628067e+02 3.15946763e+02 2.01054678e+02 6.65046821e+01\n",
      " 1.27515941e+01 1.85412349e+01 1.41147469e+00 1.15313786e+00\n",
      " 5.13102558e+00 7.93848608e-01 7.96200994e-01 7.99713929e+00\n",
      " 5.81275491e+00 2.82746671e+00]\n",
      "pvalues_: [1.95617446e-005 4.90554780e-034 6.97978312e-043 2.26012537e-060\n",
      " 1.14418718e-106 7.82499972e-025 7.88564600e-028 1.88978592e-045\n",
      " 3.40135778e-002 1.23148170e-052 5.44164620e-084 6.79932073e-099\n",
      " 1.70003538e-096 4.52463828e-001 2.57822460e-126 3.30863202e-001\n",
      " 5.03597692e-069 2.00600961e-058 3.28093546e-040 1.66217906e-015\n",
      " 3.80553511e-004 1.90519357e-005 2.35222896e-001 2.83270823e-001\n",
      " 2.38128844e-002 3.73251302e-001 3.72544527e-001 4.82178295e-003\n",
      " 1.61722184e-002 9.31195726e-002]\n",
      "selected index: [ 3  4  7  9 10 11 12 14 16 17]\n",
      "after transform: [[-4.46825973e+00  2.80533626e+00 -4.26123720e+00 ... -7.41771206e+00\n",
      "  -3.65280196e+00 -6.29314532e+00]\n",
      " [ 8.40826784e-01 -1.07632197e+00  7.01595425e-03 ...  5.96597222e-03\n",
      "   1.58943609e-02 -4.14817450e-01]\n",
      " [ 1.67752435e-01 -1.35923491e+00  1.40187729e-01 ...  5.55033127e-01\n",
      "  -6.60289431e-01 -8.64740829e-01]\n",
      " ...\n",
      " [-9.30380782e-01 -2.92113403e-01  1.44607639e+00 ... -1.13813354e+00\n",
      "   2.73022937e-01  1.84381364e-01]\n",
      " [ 5.66085595e-01 -5.68724015e-01 -5.75989432e-01 ...  2.40160760e-01\n",
      "   1.15677535e+00  4.52200691e-01]\n",
      " [ 2.15158337e-01  3.12241335e+00  8.43698466e-01 ...  1.23305510e-01\n",
      "   5.34981762e-01 -9.45938210e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(\"scores_:\",test.scores_)\n",
    "print(\"pvalues_:\",test.pvalues_)\n",
    "print(\"selected index:\",test.get_support(True))\n",
    "print(\"after transform:\",test.transform(X_under_train)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL FITTING ON TRAIN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[338   5]\n",
      " [ 41 304]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.99      0.94       343\n",
      "          1       0.98      0.88      0.93       345\n",
      "\n",
      "avg / total       0.94      0.93      0.93       688\n",
      "\n",
      "0.9331395348837209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "svclassifier = SVC(kernel='linear')  \n",
    "X = X_under_train[['V2','V3','V4','V9','V10','V11','V12','V14','V16','V17']]\n",
    "svclassifier.fit(X, y_under_train)\n",
    "y_pred = svclassifier.predict(X)\n",
    "print(confusion_matrix(y_under_train,y_pred))  \n",
    "print(classification_report(y_under_train,y_pred))  \n",
    "print(accuracy_score(y_under_train, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL FITTING ON TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[149   0]\n",
      " [ 17 130]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95       149\n",
      "          1       1.00      0.88      0.94       147\n",
      "\n",
      "avg / total       0.95      0.94      0.94       296\n",
      "\n",
      "0.9425675675675675\n"
     ]
    }
   ],
   "source": [
    "X2 = X_under_test[['V2','V3','V4','V9','V10','V11','V12','V14','V16','V17']]\n",
    "y_pred = svclassifier.predict(X2)\n",
    "print(confusion_matrix(y_under_test,y_pred))  \n",
    "print(classification_report(y_under_test,y_pred))  \n",
    "print(accuracy_score(y_under_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRIDSEARCH ON TRAIN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logreg__C': 10.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.936046511627907"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "logregpipe = Pipeline([('scale', StandardScaler()),\n",
    "                   ('logreg',LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\"))])\n",
    "\n",
    "# Gridsearch to determine the value of C\n",
    "param_grid = {'logreg__C':np.arange(0.01,100,10)}\n",
    "logreg_cv = GridSearchCV(logregpipe,param_grid,cv=5,return_train_score=True)\n",
    "logreg_cv.fit(X,y_under_train)\n",
    "print(logreg_cv.best_params_)\n",
    "\n",
    "bestlogreg = logreg_cv.best_estimator_\n",
    "bestlogreg.fit(X,y_under_train)\n",
    "bestlogreg.coef_ = bestlogreg.named_steps['logreg'].coef_\n",
    "bestlogreg.score(X,y_under_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRIDSEARCH ON TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9594594594594594"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestlogreg = logreg_cv.best_estimator_\n",
    "bestlogreg.fit(X2,y_under_test)\n",
    "bestlogreg.coef_ = bestlogreg.named_steps['logreg'].coef_\n",
    "bestlogreg.score(X2,y_under_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROSS VALIDATION ON TRAIN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-b7317f369fa1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_val_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_under_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_under_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[1;34m(estimator, X, y, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m   1374\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1376\u001b[1;33m     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1377\u001b[0m     \u001b[1;31m# We clone the estimator to make sure that all the folds are\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1378\u001b[0m     \u001b[1;31m# independent, and that it is pickle-able.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36mcheck_cv\u001b[1;34m(cv, X, y, classifier)\u001b[0m\n\u001b[0;32m   1833\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1834\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'binary'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'multiclass'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1835\u001b[1;33m                 \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1836\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1837\u001b[0m                 \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, y, n_folds, shuffle, random_state)\u001b[0m\n\u001b[0;32m    568\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtest_fold_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mper_label_splits\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mper_label_cvs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_split\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mper_label_splits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m                 \u001b[0mlabel_test_folds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_folds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m                 \u001b[1;31m# the test split can be too big because we used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m                 \u001b[1;31m# KFold(max(c, self.n_folds), self.n_folds) instead of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import cross_validation\n",
    "\n",
    "predicted = cross_validation.cross_val_predict(LogisticRegression(),X,y_under_train, cv=10)\n",
    "print (metrics.accuracy_score(y_under_train, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROSS VALIDATION ON TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-b3d9a5d1e3bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredicted1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_val_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_under_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_under_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_under_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[1;34m(estimator, X, y, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m   1374\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1376\u001b[1;33m     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1377\u001b[0m     \u001b[1;31m# We clone the estimator to make sure that all the folds are\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1378\u001b[0m     \u001b[1;31m# independent, and that it is pickle-able.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36mcheck_cv\u001b[1;34m(cv, X, y, classifier)\u001b[0m\n\u001b[0;32m   1833\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1834\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'binary'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'multiclass'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1835\u001b[1;33m                 \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1836\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1837\u001b[0m                 \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, y, n_folds, shuffle, random_state)\u001b[0m\n\u001b[0;32m    568\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtest_fold_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mper_label_splits\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mper_label_cvs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_split\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mper_label_splits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m                 \u001b[0mlabel_test_folds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_folds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m                 \u001b[1;31m# the test split can be too big because we used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m                 \u001b[1;31m# KFold(max(c, self.n_folds), self.n_folds) instead of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "predicted1 = cross_validation.cross_val_predict(LogisticRegression(),X2, y_under_test, cv=10)\n",
    "\n",
    "print (metrics.classification_report(y_under_test, predicted1))\n",
    "print (metrics.accuracy_score(y_under_test, predicted1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA ON SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.99975957e-01 2.39229298e-05 8.05575944e-08 1.07626617e-08\n",
      " 1.05801605e-08]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=5)\n",
    "X_under_train = pca.fit_transform(X_under_train)\n",
    "X_under_test = pca.transform(X_under_test)\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(explained_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL FITTING ON TRAIN & TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[148   1]\n",
      " [ 31 116]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.99      0.90       149\n",
      "          1       0.99      0.79      0.88       147\n",
      "\n",
      "avg / total       0.91      0.89      0.89       296\n",
      "\n",
      "0.8918918918918919\n"
     ]
    }
   ],
   "source": [
    "svclassifier = SVC(kernel='linear')  \n",
    "svclassifier.fit(X_under_train, y_under_train)\n",
    "y_pred = svclassifier.predict(X_under_test)\n",
    "print(confusion_matrix(y_under_test,y_pred))  \n",
    "print(classification_report(y_under_test,y_pred)) \n",
    "print(accuracy_score(y_under_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRIDSEARCH ON TEST & TRAIN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logreg__C': 40.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.938953488372093"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "logregpipe = Pipeline([('scale', StandardScaler()),\n",
    "                   ('logreg',LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\"))])\n",
    "\n",
    "# Gridsearch to determine the value of C\n",
    "param_grid = {'logreg__C':np.arange(0.01,100,10)}\n",
    "logreg_cv = GridSearchCV(logregpipe,param_grid,cv=5,return_train_score=True)\n",
    "logreg_cv.fit(X_under_train,y_under_train)\n",
    "print(logreg_cv.best_params_)\n",
    "\n",
    "bestlogreg = logreg_cv.best_estimator_\n",
    "bestlogreg.fit(X_under_train,y_under_train)\n",
    "bestlogreg.coef_ = bestlogreg.named_steps['logreg'].coef_\n",
    "bestlogreg.score(X_under_train,y_under_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROSS VALIDATION ON TEST & TRAIN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-931f244edebe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_val_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_under_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_under_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_under_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[1;34m(estimator, X, y, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m   1374\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1376\u001b[1;33m     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1377\u001b[0m     \u001b[1;31m# We clone the estimator to make sure that all the folds are\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1378\u001b[0m     \u001b[1;31m# independent, and that it is pickle-able.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36mcheck_cv\u001b[1;34m(cv, X, y, classifier)\u001b[0m\n\u001b[0;32m   1833\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1834\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'binary'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'multiclass'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1835\u001b[1;33m                 \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1836\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1837\u001b[0m                 \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, y, n_folds, shuffle, random_state)\u001b[0m\n\u001b[0;32m    568\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtest_fold_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mper_label_splits\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mper_label_cvs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_split\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mper_label_splits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m                 \u001b[0mlabel_test_folds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_folds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m                 \u001b[1;31m# the test split can be too big because we used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m                 \u001b[1;31m# KFold(max(c, self.n_folds), self.n_folds) instead of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import cross_validation\n",
    "\n",
    "predicted = cross_validation.cross_val_predict(LogisticRegression(),X_under_train,y_under_train, cv=10)\n",
    "print (metrics.accuracy_score(y_under_train, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-aa6ac1ad02ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredicted1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_val_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_under_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_under_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_under_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_under_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[1;34m(estimator, X, y, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m   1374\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1376\u001b[1;33m     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1377\u001b[0m     \u001b[1;31m# We clone the estimator to make sure that all the folds are\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1378\u001b[0m     \u001b[1;31m# independent, and that it is pickle-able.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36mcheck_cv\u001b[1;34m(cv, X, y, classifier)\u001b[0m\n\u001b[0;32m   1833\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1834\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'binary'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'multiclass'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1835\u001b[1;33m                 \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1836\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1837\u001b[0m                 \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, y, n_folds, shuffle, random_state)\u001b[0m\n\u001b[0;32m    568\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtest_fold_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mper_label_splits\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mper_label_cvs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_split\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mper_label_splits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m                 \u001b[0mlabel_test_folds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_folds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m                 \u001b[1;31m# the test split can be too big because we used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m                 \u001b[1;31m# KFold(max(c, self.n_folds), self.n_folds) instead of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "predicted1 = cross_validation.cross_val_predict(LogisticRegression(),X_under_test, y_under_test, cv=10)\n",
    "\n",
    "print (metrics.classification_report(y_under_test, predicted1))\n",
    "print (metrics.accuracy_score(y_under_test, predicted1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
